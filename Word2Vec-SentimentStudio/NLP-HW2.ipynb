{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.base import BaseEstimator\n",
    "from typing import List, Tuple, Optional, Any\n",
    "import warnings\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from gensim.models import KeyedVectors\n",
    "import gensim.models\n",
    "import gensim.downloader as api\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm import tqdm \n",
    "from gensim import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\amant\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Global package object instantiation \n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "nltk.download('stopwords')\n",
    "tqdm.pandas()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "# Precompile regular expressions for performance\n",
    "pattern_contractions = re.compile(r'\\b(' + '|'.join(contraction_mapping.keys()) + r')\\b')\n",
    "pattern_html = re.compile(r'http\\S+')\n",
    "pattern_non_alphabetic = re.compile(r'[^a-zA-Z]')\n",
    "pattern_whitespace = re.compile(r'\\s+')\n",
    "\n",
    "\n",
    "# Initialize the lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Dataset Generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['review_body', 'star_rating'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/data.tsv\", sep = '\\t', on_bad_lines = 'skip') #, nrows = 1000)#, usecols=['review_body','star_rating']) #lineterminator='\\r'\n",
    "df.drop(df.columns[0], axis = 1, inplace = True)\n",
    "df = df[['review_body', 'star_rating']]\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess/Cleaning take 15 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping = {\n",
    "    \"ain't\": \"am not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"can't've\": \"cannot have\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"couldn't've\": \"could not have\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hadn't've\": \"had not have\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'd've\": \"he would have\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he'll've\": \"he will have\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'd'y\": \"how do you\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"I'd\": \"I would\",\n",
    "    \"I'd've\": \"I would have\",\n",
    "    \"I'll\": \"I will\",\n",
    "    \"I'll've\": \"I will have\",\n",
    "    \"I'm\": \"I am\",\n",
    "    \"I've\": \"I have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"it'd've\": \"it would have\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it'll've\": \"it will have\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mightn't've\": \"might not have\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"needn't've\": \"need not have\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"oughtn't've\": \"ought not have\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"sha'n't\": \"shall not\",\n",
    "    \"shan't've\": \"shall not have\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'd've\": \"she would have\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she'll've\": \"she will have\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"shouldn't've\": \"should not have\",\n",
    "    \"so've\": \"so have\",\n",
    "    \"so's\": \"so is\",\n",
    "    \"that'd\": \"that would\",\n",
    "    \"that'd've\": \"that would have\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there'd\": \"there would\",\n",
    "    \"there'd've\": \"there would have\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'd've\": \"they would have\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they'll've\": \"they will have\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"to've\": \"to have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we'd've\": \"we would have\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we'll've\": \"we will have\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what'll\": \"what will\",\n",
    "    \"what'll've\": \"what will have\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"when've\": \"when have\",\n",
    "    \"where'd\": \"where did\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"where've\": \"where have\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who'll've\": \"who will have\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"who've\": \"who have\",\n",
    "    \"why's\": \"why is\",\n",
    "    \"why've\": \"why have\",\n",
    "    \"will've\": \"will have\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"won't've\": \"will not have\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"wouldn't've\": \"would not have\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"y'all'd\": \"you all would\",\n",
    "    \"y'all'd've\": \"you all would have\",\n",
    "    \"y'all're\": \"you all are\",\n",
    "    \"y'all've\": \"you all have\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'd've\": \"you would have\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you'll've\": \"you will have\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "\n",
    "def expand_contractions(text: str, contraction_map: dict = contraction_mapping) -> str:\n",
    "    \"\"\"\n",
    "    Expands contractions in a given text using a specified mapping.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to be processed.\n",
    "        contraction_map (dict): A dictionary where keys are contractions and values are their expanded forms.\n",
    "\n",
    "    Returns:\n",
    "        str: The processed text with contractions expanded.\n",
    "    \"\"\"\n",
    "    return pattern_contractions.sub(lambda match: contraction_map[match.group(0)], text)\n",
    "\n",
    "def remove_stopwords(text: str, stopwords: List[str]) -> str:\n",
    "    \"\"\"\n",
    "    Removes stopwords from a given text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to be processed.\n",
    "        stopwords (List[str]): A list of stopwords to be removed.\n",
    "\n",
    "    Returns:\n",
    "        str: The text with stopwords removed.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    filtered_words = [word for word in words if word not in stopwords]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "def lemmatize_text(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Lemmatizes the words in a given text.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to be processed.\n",
    "\n",
    "    Returns:\n",
    "        str: The text with words lemmatized.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(lemmatized_words)\n",
    "\n",
    "def clean_and_preprocess_reviews(reviews, stopwords: List[str]) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Cleans and preprocesses review texts.\n",
    "\n",
    "    Args:\n",
    "        reviews (pd.Series): A Pandas Series containing review texts.\n",
    "        stopwords (List[str]): A list of stopwords to be removed during preprocessing.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: The preprocessed review texts.\n",
    "    \"\"\"\n",
    "    # Cleaning\n",
    "    reviews = reviews.str.lower()\n",
    "    reviews = reviews.progress_apply(lambda x: BeautifulSoup(x, \"html.parser\").get_text())\n",
    "    reviews = reviews.replace(pattern_html, '', regex=True)\n",
    "    reviews = reviews.replace(pattern_non_alphabetic, \" \", regex=True)\n",
    "    reviews = reviews.replace(pattern_whitespace, ' ', regex=True).str.strip()\n",
    "    reviews = reviews.progress_apply(lambda x: expand_contractions(x))\n",
    "\n",
    "    # Preprocessing\n",
    "    reviews = reviews.progress_apply(lambda x: remove_stopwords(x, stopwords))\n",
    "    reviews = reviews.progress_apply(lemmatize_text)\n",
    "\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2640254/2640254 [01:47<00:00, 24548.70it/s]\n",
      "100%|██████████| 2640254/2640254 [01:15<00:00, 34828.15it/s]\n",
      "100%|██████████| 2640254/2640254 [00:19<00:00, 134135.10it/s]\n",
      "100%|██████████| 2640254/2640254 [04:09<00:00, 10584.75it/s]\n",
      "100%|██████████| 2640254/2640254 [00:01<00:00, 1436903.61it/s]\n"
     ]
    }
   ],
   "source": [
    "df['review_body'] = df['review_body'].astype(str)\n",
    "df.dropna(subset=['review_body'], inplace=True)\n",
    "df['review_body'] = clean_and_preprocess_reviews(df['review_body'], stop_words)\n",
    "df.dropna(subset=['review_body'], inplace=True)\n",
    "\n",
    "df['label'] = df['star_rating'].progress_apply(lambda x: 0 if x in [4, 5] else (1 if x in [1, 2] else 2))\n",
    "samples = [df[df['star_rating'] == rating].sample(n = 50000, random_state=42) for rating in [5, 4, 3, 2, 1]]\n",
    "merged_dataset = pd.concat(samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "Load the pretrained “word2vec-google-news-300” Word2Vec model and learn\n",
    "how to extract word embeddings for your dataset. Try to check semantic\n",
    "similarities of the generated vectors using two examples of your own, e.g.,\n",
    "King − M an + W oman = Queen or excellent ∼ outstanding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'Ocean' and 'Sea':  0.76435417\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = api.load('word2vec-google-news-300')\n",
    "print(\"Similarity between 'Ocean' and 'Sea': \", pretrained_model.similarity('ocean', 'sea'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)\n",
    "Check the semantic similarities for the same two examples\n",
    "in part (a). What do you conclude from comparing vectors generated by\n",
    "yourself and the pretrained model? Which of the Word2Vec models seems\n",
    "to encode semantic similarities between words better?\n",
    "\n",
    "In the pretrained model, the similarity score between Outstanding and Excellent was lower than the custom model I trained, thus showing that similarities between vectors were stronger in my model. But the pretrained model does a better join of building relationships between words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCorpus:\n",
    "    def __init__(self, df, col):\n",
    "        self.df = df\n",
    "        self.col = col\n",
    "\n",
    "    def __iter__(self):\n",
    "        for line in self.df[self.col]:\n",
    "            yield utils.simple_preprocess(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = gensim.models.Word2Vec(sentences = MyCorpus(merged_dataset, 'review_body'), vector_size = 300, window = 11, min_count = 10, workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'ocean' and 'sea': 0.5721045\n"
     ]
    }
   ],
   "source": [
    "word_vectors = my_model.wv\n",
    "\n",
    "print(\"Similarity between 'ocean' and 'sea':\", word_vectors.similarity('ocean', 'sea'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def document_vector(word2vec_model: KeyedVectors, doc_review: List[str]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generates a document vector by averaging the vectors of words in the document\n",
    "    that are present in the word2vec model.\n",
    "\n",
    "    Args:\n",
    "        word2vec_model (KeyedVectors): A word2vec model.\n",
    "        doc_review (List[str]): A list of words in the document.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The averaged vector of the document.\n",
    "    \"\"\"\n",
    "    doc_review = [word for word in doc_review if word in word2vec_model.key_to_index]\n",
    "    \n",
    "    if not doc_review:\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "        \n",
    "    return np.mean(word2vec_model[doc_review], axis=0)\n",
    "\n",
    "def gen_concat_feature_vector(word2vec_model: KeyedVectors, doc_review: List[str], vector_size: int = 300, max_words: int = 10) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Generates a concatenated feature vector for the first 'max_words' words in a document,\n",
    "    using the word vectors from the provided word2vec model.\n",
    "\n",
    "    Args:\n",
    "        word2vec_model (KeyedVectors): A word2vec model.\n",
    "        doc_review (List[str]): A list of words in the document.\n",
    "        vector_size (int): The size of the word vectors.\n",
    "        max_words (int): The maximum number of word vectors to concatenate.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The concatenated vector of the document.\n",
    "    \"\"\"\n",
    "    concatenated_vector = np.zeros(vector_size * max_words)\n",
    "    \n",
    "    for i, word in enumerate(doc_review[:max_words]):\n",
    "        if word in word2vec_model.key_to_index:\n",
    "            concatenated_vector[i * vector_size:(i + 1) * vector_size] = word2vec_model[word]\n",
    "            \n",
    "    return concatenated_vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve all word embeddings for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250000/250000 [00:08<00:00, 28351.26it/s]\n",
      "100%|██████████| 250000/250000 [00:20<00:00, 12061.32it/s]\n",
      "100%|██████████| 250000/250000 [00:19<00:00, 12603.98it/s]\n",
      "100%|██████████| 250000/250000 [00:13<00:00, 19024.73it/s]\n",
      "100%|██████████| 250000/250000 [00:17<00:00, 14404.71it/s]\n"
     ]
    }
   ],
   "source": [
    "merged_dataset['processed_text'] = merged_dataset['review_body'].progress_apply(gensim.utils.simple_preprocess)\n",
    "merged_dataset['pretrained_vector'] = merged_dataset['processed_text'].progress_apply(lambda doc_review: document_vector(pretrained_model, doc_review))\n",
    "merged_dataset['custom_vector'] = merged_dataset['processed_text'].progress_apply(lambda doc_review: document_vector(my_model.wv, doc_review))\n",
    "merged_dataset['pre_concatenated_vector'] = merged_dataset['processed_text'].progress_apply(lambda row_indx: gen_concat_feature_vector(pretrained_model, row_indx))\n",
    "merged_dataset['custom_concatenated_vector'] = merged_dataset['processed_text'].progress_apply(lambda row_indx: gen_concat_feature_vector(pretrained_model, row_indx)) \n",
    "\n",
    "### Create the binary labels ###\n",
    "filtered_dataset = merged_dataset[merged_dataset['label'] != 2]\n",
    "filtered_dataset['binary_label'] = filtered_dataset['label'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Simple models \n",
    "\n",
    "What do you conclude from comparing performances for the models\n",
    "trained using the three different feature types (TF-IDF, pretrained Word2Vec,\n",
    "your trained Word2Vec)?\n",
    "\n",
    "It seems tha pretrained Word2Vec embeddings marginally perform better than the custom models embeddings and better than TF-IDF \n",
    "most likely due to the moderately large window size that is being used in the Word2Vec model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_label: np.ndarray, y_predicted: np.ndarray) -> Tuple[float, float, float, float]:\n",
    "    \"\"\"\n",
    "    Evaluates the performance of a model using accuracy, precision, recall, and F1 score.\n",
    "\n",
    "    Args:\n",
    "        y_label (np.ndarray): The true labels.\n",
    "        y_predicted (np.ndarray): The predicted labels by the model.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[float, float, float, float]: A tuple containing accuracy, precision, recall, and F1 score.\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_label, y_predicted)\n",
    "    precision = precision_score(y_label, y_predicted, average='weighted')\n",
    "    recall = recall_score(y_label, y_predicted, average='weighted')\n",
    "    f1 = f1_score(y_label, y_predicted, average='weighted')\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "def sklearn_model_train(X: np.ndarray, Y: np.ndarray, model_types: List[Tuple[str, BaseEstimator]], prefix: str, test_size: float = 0.2, random_state: int = 42) -> None:\n",
    "    \"\"\"\n",
    "    Trains and evaluates models specified in model_types on the provided dataset, \n",
    "    printing the accuracy of each model.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): Feature vectors of the dataset.\n",
    "        Y (np.ndarray): Labels of the dataset.\n",
    "        model_types (List[Tuple[str, BaseEstimator]]): A list of tuples containing model names and their instances.\n",
    "        prefix (str): A prefix string for printing model performance.\n",
    "        test_size (float): The proportion of the dataset to include in the test split.\n",
    "        random_state (int): Controls the shuffling applied to the data before applying the split.\n",
    "    \"\"\"\n",
    "    # Splitting the dataset into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    for name, model in model_types:\n",
    "        model.fit(X_train, y_train.ravel()) \n",
    "        y_pred_test = model.predict(X_test)\n",
    "        te_acc, _, _, _ = evaluate(y_test, y_pred_test)\n",
    "\n",
    "    \n",
    "        print(f\"{prefix} {name} Testing: Accuracy: {te_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ternary Custom Embedding Perceptron Model Testing: Accuracy: 0.6327\n",
      "Ternary Custom Embedding SVM Model Testing: Accuracy: 0.3597\n",
      "Ternary Pretrained Embedding Perceptron Model Testing: Accuracy: 0.5828\n",
      "Ternary Pretrained Embedding SVM Model Testing: Accuracy: 0.2840\n",
      "Binary Custom Embedding Perceptron Model Testing: Accuracy: 0.7805\n",
      "Binary Custom Embedding SVM Model Testing: Accuracy: 0.6251\n",
      "Binary Pretrained Embedding Perceptron Model Testing: Accuracy: 0.7404\n",
      "Binary Pretrained Embedding SVM Model Testing: Accuracy: 0.5642\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_names = [\n",
    "    (\"Perceptron Model\", Perceptron()),\n",
    "    (\"SVM Model\", SVC(max_iter = 1000))\n",
    "]\n",
    "\n",
    "# Train and evaluate models for ternary labels\n",
    "sklearn_model_train(np.vstack(merged_dataset['custom_vector'].values), np.vstack( merged_dataset['label'].values), model_names, prefix='Ternary Custom Embedding')\n",
    "sklearn_model_train(np.vstack(merged_dataset['pretrained_vector'].values), np.vstack( merged_dataset['label'].values), model_names, prefix='Ternary Pretrained Embedding')\n",
    "\n",
    "# Train and evaluate models for binary labels\n",
    "sklearn_model_train(np.vstack(filtered_dataset['custom_vector'].values),  np.vstack(filtered_dataset['binary_label'].values), model_names, prefix='Binary Custom Embedding')\n",
    "sklearn_model_train(np.vstack(filtered_dataset['pretrained_vector'].values), np.vstack(filtered_dataset['binary_label'].values), model_names, prefix='Binary Pretrained Embedding')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Feedforward Neural Network Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=300, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (fc3): Linear(in_features=10, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple feedforward neural network for classification tasks.\n",
    "\n",
    "    Attributes:\n",
    "        n_classes (int): The number of output classes.\n",
    "        n_dim (int): The dimensionality of the input features.\n",
    "        fc1 (nn.Linear): The first fully connected layer.\n",
    "        fc2 (nn.Linear): The second fully connected layer.\n",
    "        fc3 (nn.Linear): The third fully connected layer, producing the output.\n",
    "        dropout (nn.Dropout): Dropout layer for regularization.\n",
    "\n",
    "    Args:\n",
    "        n_classes (int): The number of classes in the target classification task.\n",
    "        n_dim (int): The size of each input sample.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_classes: int, n_dim: int):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        hidden_1 = 50\n",
    "        hidden_2 = 10\n",
    "\n",
    "        self.n_classes = n_classes\n",
    "        self.n_dim = n_dim\n",
    "\n",
    "        # Define layers\n",
    "        self.fc1 = nn.Linear(n_dim, hidden_1)\n",
    "        self.fc2 = nn.Linear(hidden_1, hidden_2)\n",
    "        self.fc3 = nn.Linear(hidden_2, n_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Defines the forward pass of the network. Utilizing GeLu activation\n",
    "        functions for NLP task specific nonlinearity \n",
    "\n",
    "        Args:\n",
    "            x (Tensor): The input tensor containing the features of the input samples.\n",
    "\n",
    "        Returns:\n",
    "            Tensor: The output tensor after passing through the network.\n",
    "        \"\"\"\n",
    "        \n",
    "        x = f.gelu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = f.gelu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = f.softmax(self.fc3(x)) \n",
    "        return x\n",
    "\n",
    "\n",
    "ternary_model = Net(n_classes = 3, n_dim = 300)\n",
    "binary_model = Net(n_classes = 2, n_dim = 300)\n",
    "concat_ternary_model = Net(n_classes = 3, n_dim = 3000)\n",
    "concat_binary_model = Net(n_classes = 2, n_dim = 3000)\n",
    "\n",
    "print(ternary_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom dataset class for text data to be used with PyTorch DataLoader.\n",
    "\n",
    "    Attributes:\n",
    "        features (torch.Tensor): Tensor containing all input features.\n",
    "        labels (torch.Tensor): Tensor containing all labels.\n",
    "    \"\"\"\n",
    "    def __init__(self, features: torch.Tensor, labels: torch.Tensor):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "def model_preprocess(x: List, y: List, model: nn.Module, cnn_bit: int = 0, optimi: Optional[torch.optim.Optimizer] = None) -> Tuple[DataLoader, DataLoader, nn.Module, torch.optim.Optimizer]:\n",
    "    \"\"\"\n",
    "    Prepares and preprocesses the dataset for training and validation, including creating DataLoader instances.\n",
    "\n",
    "    Args:\n",
    "        x (List): Input features as a list of tensors.\n",
    "        y (List): Corresponding labels as a list.\n",
    "        model (nn.Module): The PyTorch model to be trained.\n",
    "        cnn_bit (int, optional): Flag to select the optimizer type. Defaults to 0.\n",
    "        optimi (Optional[torch.optim.Optimizer], optional): Optionally, a specific optimizer can be provided. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[DataLoader, DataLoader, nn.Module, torch.optim.Optimizer]: A tuple containing training and test DataLoader, the loss criterion, and the optimizer.\n",
    "    \"\"\"\n",
    "\n",
    "    # Split the dataset into training and test sets\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "    \n",
    "    # Convert lists to tensors\n",
    "    x_train = torch.tensor(x_train, dtype=torch.float32)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "    x_test = torch.tensor(x_test, dtype=torch.float32)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "    # Create DataLoader instances for training and test sets\n",
    "    train_loader = DataLoader(TextDataset(x_train, y_train), batch_size=64, shuffle=True)\n",
    "    test_loader = DataLoader(TextDataset(x_test, y_test), batch_size=64, shuffle=False)\n",
    "\n",
    "    # Determine the optimizer\n",
    "    if optimi is None:\n",
    "        if cnn_bit == 1:\n",
    "            optimi = torch.optim.Adadelta(model.parameters(), lr = 0.25, rho = 0.95)\n",
    "        else:\n",
    "            optimi = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
    "\n",
    "    return train_loader, test_loader, nn.CrossEntropyLoss(), optimi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(hyperparams: Tuple[DataLoader, DataLoader, nn.Module, torch.optim.Optimizer], \n",
    "                model: nn.Module, \n",
    "                debug_mode: int = 0, \n",
    "                n_epochs: int = 50) -> float:\n",
    "    \"\"\"\n",
    "    Trains a given PyTorch model with specified hyperparameters, and evaluates it on a test set.\n",
    "\n",
    "    Args:\n",
    "        hyperparams (Tuple[DataLoader, DataLoader, nn.Module, torch.optim.Optimizer]): \n",
    "            A tuple containing training and testing DataLoaders, the loss criterion, and the optimizer.\n",
    "        model (nn.Module): The neural network model to be trained and evaluated.\n",
    "        debug_mode (int, optional): If set to 1, prints detailed training progress and accuracy. Defaults to 0.\n",
    "        n_epochs (int, optional): Number of epochs for training the model. Defaults to 50.\n",
    "\n",
    "    Returns:\n",
    "        float: The accuracy of the model on the test set after the final epoch of training.\n",
    "    \"\"\"\n",
    "    train_loader, test_loader, criterion, optimizer = hyperparams\n",
    "    valid_loss_min = np.inf\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        # Initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        correct_train = 0\n",
    "        correct_valid = 0\n",
    "        total_train = 0\n",
    "        total_valid = 0\n",
    "\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        for data, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item() * data.size(0)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            correct_train += (predicted == target).sum().item()\n",
    "            total_train += target.size(0)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                valid_loss += loss.item() * data.size(0)\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                correct_valid += (predicted == target).sum().item()\n",
    "                total_valid += target.size(0)\n",
    "\n",
    "        # Calculate average losses\n",
    "        train_loss = train_loss / total_train\n",
    "        valid_loss = valid_loss / total_valid\n",
    "        train_accuracy = correct_train / total_train\n",
    "        valid_accuracy = correct_valid / total_valid\n",
    "\n",
    "        # Print training/validation statistics \n",
    "        if debug_mode == 1:\n",
    "            print(f'Epoch: {epoch + 1}/{n_epochs} \\tTraining Loss: {train_loss:.6f} \\tTraining Accuracy: {train_accuracy * 100:.2f}% \\tValidation Loss: {valid_loss:.6f} \\tValidation Accuracy: {valid_accuracy * 100:.2f}%')\n",
    "\n",
    "            # Save model if validation loss has decreased\n",
    "            if valid_loss <= valid_loss_min:\n",
    "                print('Validation loss decreased ({:.6f} --> {:.6f}). Saving model ...'.format(valid_loss_min, valid_loss))\n",
    "                torch.save(model.state_dict(), 'model.pt')\n",
    "                valid_loss_min = valid_loss\n",
    "\n",
    "    return valid_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Embeddings and 3 Class MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6971"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hyperparameters_tern_custom = model_preprocess(merged_dataset['custom_vector'].values, merged_dataset['label'].values, ternary_model )\n",
    "train_model(model_hyperparameters_tern_custom, ternary_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained Embeddings and 3 Class MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.66548"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hyperparameters_tern_pre = model_preprocess(merged_dataset['pretrained_vector'].values, merged_dataset['label'].values, ternary_model)\n",
    "train_model(model_hyperparameters_tern_pre, ternary_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Embeddings and 2 Class MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.86325"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hyperparameters_bin_custom = model_preprocess(filtered_dataset['custom_vector'].values, filtered_dataset['binary_label'].values, binary_model)\n",
    "train_model(model_hyperparameters_bin_custom, binary_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained Embeddings and 2 Class MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.822525"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hyperparameters_bin_pre = model_preprocess(filtered_dataset['pretrained_vector'].values, filtered_dataset['binary_label'].values, binary_model)\n",
    "train_model(model_hyperparameters_bin_pre, binary_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) (15 points)\n",
    "What do you conclude by comparing accuracy values you obtain with\n",
    "those obtained in the “’Simple Models” section (note you can compare the\n",
    "accuracy values for binary classification)\n",
    "\n",
    "In the ternary classifiation, simple models perform worse by an average of 10% in their validation accuracies. This is due to the unique choice of hyperparamters (hidden dimensions, nonlinerity and learning etc) that pytorch allows us to customize. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained Concatenated Embeddings and 2 Class MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.786475"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hyperp_concat_bin_pre = model_preprocess(filtered_dataset['pre_concatenated_vector'].values, filtered_dataset['binary_label'].values, concat_binary_model)\n",
    "train_model(model_hyperp_concat_bin_pre, concat_binary_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Concatenated Embeddings and 2 Class MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.854975"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hyperp_concat_bin_custom = model_preprocess(filtered_dataset['custom_concatenated_vector'].values, filtered_dataset['binary_label'].values, concat_binary_model, optimi = torch.optim.SGD(concat_binary_model.parameters(), lr = 0.001))\n",
    "train_model(model_hyperp_concat_bin_custom, concat_binary_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained Concatenated Embeddings and 3 Class MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.68756"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hyperp_concat_ter_pre = model_preprocess(merged_dataset['pre_concatenated_vector'].values, merged_dataset['label'].values, concat_ternary_model, optimi = torch.optim.Adam(concat_ternary_model.parameters(), lr = 0.001))\n",
    "train_model(model_hyperp_concat_ter_pre, concat_ternary_model, n_epochs = 1, debug_mode = 0) #0.68756"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Concatenated Embeddings and 3 Class MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.62498"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hyperp_concat_ter_custom = model_preprocess(merged_dataset['custom_concatenated_vector'].values, merged_dataset['label'].values, concat_ternary_model)\n",
    "train_model(model_hyperp_concat_ter_custom, concat_ternary_model, n_epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.conv1 = nn.Conv1d(1, 50, kernel_size = 5, padding = 2) ## 50 words store as 300 dim wv's \n",
    "        self.conv2 = nn.Conv1d(50, 10, kernel_size = 5, padding = 2) \n",
    "        self.fc = nn.Linear(3000, self.num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.squeeze()  \n",
    "        # x = self.embedding(x).permute(0, 2, 1)\n",
    "        x = x.reshape(x.shape[0], 1 , x.shape[1])\n",
    "        x = F.gelu(self.conv1(x))\n",
    "        x = F.gelu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom embeddings & 3 Class CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.68908"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNNnet_ter_custom_complex = CNN(num_classes = 3)\n",
    "cnn_hyperp_ter_cus = model_preprocess(x = merged_dataset['custom_vector'].values, y = merged_dataset['label'].values, model = CNNnet_ter_custom_complex, cnn_bit = 1)\n",
    "train_model(hyperparams = cnn_hyperp_ter_cus, model = CNNnet_ter_custom_complex, n_epochs = 20 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom embeddings & 2 Class CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.855325"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNNnet_bin_custom = CNN(num_classes = 2)\n",
    "cnn_hyperp_bin_cust = model_preprocess(x = filtered_dataset['custom_vector'].values, y = filtered_dataset['label'].values, model = CNNnet_bin_custom, cnn_bit = 1)\n",
    "train_model(hyperparams = cnn_hyperp_bin_cust, model = CNNnet_bin_custom, n_epochs = 15) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained embeddings & 2 Class CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8189"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNNnet_bin_pre = CNN(num_classes = 2)\n",
    "cnn_hyperp_bin_pre = model_preprocess(x = filtered_dataset['pretrained_vector'].values, y = filtered_dataset['label'].values, model = CNNnet_bin_pre, cnn_bit = 1)\n",
    "train_model(hyperparams = cnn_hyperp_bin_pre, model = CNNnet_bin_pre, n_epochs = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained embeddings & 3 Class CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.67174"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNNnet_ter_pre = CNN(num_classes = 3)\n",
    "cnn_hyperp_ter_pre = model_preprocess(x = merged_dataset['pretrained_vector'].values, y = merged_dataset['label'].values, model = CNNnet_ter_pre, cnn_bit = 1)\n",
    "train_model(hyperparams = cnn_hyperp_ter_pre, model = CNNnet_ter_pre, n_epochs = 35) # 66.71"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
