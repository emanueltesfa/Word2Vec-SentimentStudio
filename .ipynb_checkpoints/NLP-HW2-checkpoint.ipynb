{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "import gensim.models\n",
    "import gensim.downloader as api\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as f \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from gensim.downloader import load\n",
    "from sklearn.svm import SVC\n",
    "from tqdm import tqdm \n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda\")\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Dataset Generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['review_body', 'star_rating'], dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"amazon_reviews_us_Office_Products_v1_00.tsv\", sep='\\t', on_bad_lines='skip')#, usecols=['review_body','star_rating']) #lineterminator='\\r'\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "df = df[['review_body', 'star_rating']]\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess/Cleaning take 15 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to punkt...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "100%|██████████| 2640254/2640254 [01:27<00:00, 30072.15it/s]\n",
      "100%|██████████| 2640254/2640254 [01:38<00:00, 26825.53it/s]\n",
      "100%|██████████| 2640254/2640254 [00:16<00:00, 161567.99it/s]\n",
      "100%|██████████| 2640254/2640254 [03:14<00:00, 13589.69it/s]\n"
     ]
    }
   ],
   "source": [
    "contraction_mapping = {\n",
    "    \"ain't\": \"am not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"cannot\",\n",
    "    \"can't've\": \"cannot have\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"couldn't've\": \"could not have\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hadn't've\": \"had not have\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'd've\": \"he would have\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he'll've\": \"he will have\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'd'y\": \"how do you\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"I'd\": \"I would\",\n",
    "    \"I'd've\": \"I would have\",\n",
    "    \"I'll\": \"I will\",\n",
    "    \"I'll've\": \"I will have\",\n",
    "    \"I'm\": \"I am\",\n",
    "    \"I've\": \"I have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"it'd've\": \"it would have\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it'll've\": \"it will have\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mightn't've\": \"might not have\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"needn't've\": \"need not have\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"oughtn't've\": \"ought not have\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"sha'n't\": \"shall not\",\n",
    "    \"shan't've\": \"shall not have\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'd've\": \"she would have\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she'll've\": \"she will have\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"shouldn't've\": \"should not have\",\n",
    "    \"so've\": \"so have\",\n",
    "    \"so's\": \"so is\",\n",
    "    \"that'd\": \"that would\",\n",
    "    \"that'd've\": \"that would have\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there'd\": \"there would\",\n",
    "    \"there'd've\": \"there would have\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'd've\": \"they would have\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they'll've\": \"they will have\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"to've\": \"to have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we'd've\": \"we would have\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we'll've\": \"we will have\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what'll\": \"what will\",\n",
    "    \"what'll've\": \"what will have\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"when've\": \"when have\",\n",
    "    \"where'd\": \"where did\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"where've\": \"where have\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who'll've\": \"who will have\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"who've\": \"who have\",\n",
    "    \"why's\": \"why is\",\n",
    "    \"why've\": \"why have\",\n",
    "    \"will've\": \"will have\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"won't've\": \"will not have\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"wouldn't've\": \"would not have\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"y'all'd\": \"you all would\",\n",
    "    \"y'all'd've\": \"you all would have\",\n",
    "    \"y'all're\": \"you all are\",\n",
    "    \"y'all've\": \"you all have\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'd've\": \"you would have\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you'll've\": \"you will have\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\"\n",
    "}\n",
    "\n",
    "\n",
    "pattern_contractions = re.compile('(%s)' % '|'.join(contraction_mapping.keys()))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "nltk.download('stopwords', 'punkt')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def expand_contractions(text, contraction_map=contraction_mapping):\n",
    "    return pattern_contractions.sub(lambda occurrence: contraction_map[occurrence.group(0)], text)\n",
    "\n",
    "\n",
    "def rem_stopwords(review,stp):\n",
    "    words = review.split()\n",
    "    filtered_words = [word for word in words if word not in stp]\n",
    "    filtered_sentence = ' '.join(filtered_words)\n",
    "    return filtered_sentence\n",
    "\n",
    "\n",
    "def lemmazation(review):\n",
    "    words = review.split()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    lemmatized_review = ' '.join(lemmatized_words)\n",
    "    return lemmatized_review\n",
    "\n",
    "\n",
    "def clean_preproc_reviews(reviews, stp):\n",
    "    ### CLEANING\n",
    "    reviews = reviews.str.lower()\n",
    "    reviews = reviews.progress_apply(lambda x: BeautifulSoup(x, \"html.parser\").get_text())\n",
    "    reviews = reviews.replace(r'http\\S+', '', regex = True)\n",
    "    reviews = reviews.replace(\"[^a-zA-Z]\", \" \", regex = True)\n",
    "    reviews = reviews.replace('\\s+', ' ', regex = True).str.strip()\n",
    "    reviews = reviews.progress_apply(lambda x: expand_contractions(x))\n",
    "\n",
    "    ### PREPROCESSING\n",
    "    reviews = reviews.progress_apply(lambda x : rem_stopwords(x, stp))\n",
    "    reviews = reviews.progress_apply(lemmazation)\n",
    "\n",
    "    return reviews\n",
    "\n",
    "# Clean the reviews\n",
    "df['review_body'] = df['review_body'].astype(str)\n",
    "df.dropna(subset=['review_body'], inplace = True)\n",
    "df['review_body'] =  clean_preproc_reviews(df['review_body'], stop_words) #df['review_body'].progress_apply(lambda x: clean_preproc_reviews(x, stop_words) )\n",
    "\n",
    "df.dropna(subset = ['review_body'], inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2640254 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2640254/2640254 [00:01<00:00, 1531487.01it/s]\n"
     ]
    }
   ],
   "source": [
    "df['label'] = df['star_rating'].progress_apply(lambda x: 0 if x in [4, 5] else (1 if x in [1, 2] else 2))\n",
    "\n",
    "star_ratings = [5, 4, 3, 2, 1]\n",
    "samples = [ df[df['star_rating'] == rating].sample(n = 50000, random_state = 42) for rating in star_ratings]\n",
    "merged_dataset = pd.concat(samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a)\n",
    "Load the pretrained “word2vec-google-news-300” Word2Vec model and learn\n",
    "how to extract word embeddings for your dataset. Try to check semantic\n",
    "similarities of the generated vectors using two examples of your own, e.g.,\n",
    "King − M an + W oman = Queen or excellent ∼ outstanding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'hey' and 'hello':  0.76435417\n"
     ]
    }
   ],
   "source": [
    "pretrained_model = api.load('word2vec-google-news-300')\n",
    "\n",
    "print(\"Similarity between 'hey' and 'hello': \", pretrained_model.similarity('ocean', 'sea'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)\n",
    "Check the semantic similarities for the same two examples\n",
    "in part (a). What do you conclude from comparing vectors generated by\n",
    "yourself and the pretrained model? Which of the Word2Vec models seems\n",
    "to encode semantic similarities between words better?\n",
    "\n",
    "In the pretrained model, the similarity score between Outstanding and Excellent was lower than the custom model I trained, thus showing that similarities between vectors were stronger in my model. But the pretrained model does a better join of building relationships between words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCorpus:\n",
    "    def __init__(self, df, col):\n",
    "        self.df = df\n",
    "        self.col = col\n",
    "\n",
    "    def __iter__(self):\n",
    "        for line in self.df[self.col]:\n",
    "            yield utils.simple_preprocess(line)\n",
    "\n",
    "\n",
    "my_model = gensim.models.Word2Vec(sentences = MyCorpus(merged_dataset, 'review_body'), vector_size = 300, window = 11, min_count = 10, workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity between 'ocean' and 'sea': 0.49394572\n"
     ]
    }
   ],
   "source": [
    "word_vectors = my_model.wv\n",
    "\n",
    "print(\"Similarity between 'ocean' and 'sea':\", word_vectors.similarity('ocean', 'sea'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/250000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250000/250000 [00:07<00:00, 33326.67it/s]\n",
      "100%|██████████| 250000/250000 [00:15<00:00, 16008.45it/s]\n",
      "100%|██████████| 250000/250000 [00:14<00:00, 16734.70it/s]\n",
      "100%|██████████| 250000/250000 [00:07<00:00, 35505.33it/s]\n",
      "100%|██████████| 250000/250000 [00:15<00:00, 16540.32it/s]\n"
     ]
    }
   ],
   "source": [
    "def document_vector(word2vec_model, doc_review):\n",
    "    doc_review = [word for word in doc_review if word in word2vec_model.key_to_index]\n",
    "    \n",
    "    if len(doc_review) == 0:\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "        \n",
    "    return np.mean(word2vec_model[doc_review], axis=0)\n",
    "\n",
    "\n",
    "def gen_concat_feature_vector(word2vec_model, doc_review, vector_size=300, max_words=10):\n",
    "    concatenated_vector = np.zeros(vector_size * max_words) # Initialize an empty array for the concatenated vectors.\n",
    "\n",
    "    for i, word in enumerate(doc_review[:max_words]):\n",
    "        if word in word2vec_model.key_to_index:\n",
    "            concatenated_vector[i*vector_size:(i+1)*vector_size] = word2vec_model[word]\n",
    "            \n",
    "    return concatenated_vector\n",
    "\n",
    "\n",
    "merged_dataset['processed_text'] = merged_dataset['review_body'].progress_apply(gensim.utils.simple_preprocess)\n",
    "merged_dataset['pretrained_vector'] = merged_dataset['processed_text'].progress_apply(lambda doc_review: document_vector(pretrained_model, doc_review))\n",
    "merged_dataset['custom_vector'] = merged_dataset['processed_text'].progress_apply(lambda doc_review: document_vector(my_model.wv, doc_review))\n",
    "#####\n",
    "merged_dataset['pre_concatenated_vector'] = merged_dataset['processed_text'].progress_apply(lambda row_indx: gen_concat_feature_vector(pretrained_model, row_indx))\n",
    "merged_dataset['custom_concatenated_vector'] = merged_dataset['processed_text'].progress_apply(lambda row_indx: gen_concat_feature_vector(pretrained_model, row_indx))\n",
    "\n",
    "X = np.vstack( merged_dataset['custom_vector'] )\n",
    "X_pre = np.vstack( merged_dataset['pretrained_vector']) \n",
    "Y = np.vstack( merged_dataset['label'] ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_dataset['binary_label'] = merged_dataset['label'].progress_apply(lambda x: pd.NA if x == 2 else (0 if x == 0 else 1))\n",
    "filtered_dataset = merged_dataset[merged_dataset['label'] != 2]\n",
    "filtered_dataset['binary_label'] = filtered_dataset['label'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Simple models \n",
    "\n",
    "What do you conclude from comparing performances for the models\n",
    "trained using the three different feature types (TF-IDF, pretrained Word2Vec,\n",
    "your trained Word2Vec)?\n",
    "\n",
    "It seems tha pretrained Word2Vec embeddings marginally perform better than the custom models embeddings and better than TF-IDF \n",
    "most likely due to the moderately large window size that is being used in the Word2Vec model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaulate(y_label, y_predicted):\n",
    "    accuracy = accuracy_score(y_label, y_predicted)\n",
    "    precision = precision_score(y_label, y_predicted, average = 'weighted')\n",
    "    recall = recall_score(y_label, y_predicted, average = 'weighted')\n",
    "    f1 = f1_score(y_label, y_predicted, average = 'weighted')\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "\n",
    "def sklearn_model_train(data, model_type, prefix):\n",
    "    for name, model_name in model_type:\n",
    "        X_train, X_test, y_train, y_test = data \n",
    "        model_name.fit(X_train, y_train)\n",
    "        y_pred_test = model_name.predict(X_test)\n",
    "        te_acc, _, _, _ = evaulate(y_test, y_pred_test)\n",
    "\n",
    "        print(prefix,name, \"Testing: Accuracy: {:.4f}\".format(te_acc) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ternary Pretrained Embedding Perceptron Model Testing: Accuracy: 0.5828\n",
      "Ternary Pretrained Embedding SVM Model Testing: Accuracy: 0.2794\n",
      "Ternary Custom Embedding Perceptron Model Testing: Accuracy: 0.5787\n",
      "Ternary Custom Embedding SVM Model Testing: Accuracy: 0.3763\n",
      "Binary Pretrained Embedding Perceptron Model Testing: Accuracy: 0.7404\n",
      "Binary Pretrained Embedding SVM Model Testing: Accuracy: 0.5747\n",
      "Binary Custom Embedding Perceptron Model Testing: Accuracy: 0.7853\n",
      "Binary Custom Embedding SVM Model Testing: Accuracy: 0.6236\n"
     ]
    }
   ],
   "source": [
    "split_data_custom = train_test_split(X, Y, test_size = 0.2, random_state = 42)\n",
    "pretrain_split_data = train_test_split(X_pre, Y, test_size = 0.2, random_state = 42)\n",
    "pretrain_bin = train_test_split(np.vstack(filtered_dataset['pretrained_vector'].values), np.vstack( filtered_dataset['binary_label'].values ), test_size = 0.2, random_state = 42)\n",
    "custom_bin = train_test_split(np.vstack( filtered_dataset['custom_vector'].values), np.vstack(filtered_dataset['binary_label'].values), test_size = 0.2, random_state = 42)\n",
    "\n",
    "\n",
    "model_names = [\n",
    "    (\"Perceptron Model\", Perceptron()), \n",
    "    (\"SVM Model\", SVC(max_iter = 500))\n",
    "]\n",
    "\n",
    "sklearn_model_train(pretrain_split_data, model_names, prefix = 'Ternary Pretrained Embedding')\n",
    "sklearn_model_train(split_data_custom, model_names, prefix = 'Ternary Custom Embedding')\n",
    "sklearn_model_train(pretrain_bin, model_names, prefix = 'Binary Pretrained Embedding')\n",
    "sklearn_model_train(custom_bin, model_names, prefix = 'Binary Custom Embedding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Feedforward Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=300, out_features=50, bias=True)\n",
      "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (fc3): Linear(in_features=10, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module): \n",
    "    def __init__(self, n_classes, n_dim):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        hidden_1 = 50\n",
    "        hidden_2 = 10\n",
    "\n",
    "        self.n_classes = n_classes\n",
    "        self.n_dim = n_dim\n",
    "\n",
    "        self.fc1 = nn.Linear(n_dim, hidden_1)\n",
    "        self.fc2 = nn.Linear(hidden_1, hidden_2)\n",
    "        self.fc3 = nn.Linear(hidden_2, n_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = f.gelu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = f.gelu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = f.softmax(self.fc3(x)) # REMOVE SOFTMAX?\n",
    "        return x \n",
    "\n",
    "\n",
    "ternary_model = Net(n_classes = 3, n_dim = 300)\n",
    "binary_model = Net(n_classes = 2, n_dim = 300)\n",
    "concat_ternary_model = Net(n_classes = 3, n_dim = 3000)\n",
    "concat_binary_model = Net(n_classes = 2, n_dim = 3000)\n",
    "\n",
    "print(ternary_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_preprocess(x, y, model, cnn_bit:int = 0, optimi = None):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "    x_train = torch.tensor(np.array(x_train.tolist(), dtype=np.float32), dtype=torch.float32)\n",
    "    y_train = torch.tensor(np.array(y_train), dtype=torch.long)\n",
    "    x_test = torch.tensor(np.array(x_test.tolist(), dtype=np.float32), dtype=torch.float32)\n",
    "    y_test = torch.tensor(np.array(y_test), dtype=torch.long)\n",
    "\n",
    "    train_loader = DataLoader(TextDataset(x_train, y_train), batch_size = 64, shuffle=True)\n",
    "    test_loader = DataLoader(TextDataset(x_test, y_test), batch_size = 64, shuffle=False)\n",
    "    \n",
    "    if optimi is None:\n",
    "        optimi = torch.optim.Adadelta(model.parameters(), lr=0.25, rho=0.95) if cnn_bit == 1 else torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
    "        # print(optimi)\n",
    "\n",
    "    return (train_loader, test_loader, nn.CrossEntropyLoss(), optimi)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(hyperparams, model, debug_mode = 0, n_epochs = 50):\n",
    "    train_loader, test_loader, criterion, optimizer = hyperparams\n",
    "    valid_loss_min = np.Inf\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        correct_train = 0\n",
    "        correct_valid = 0\n",
    "\n",
    "        # Set model to training mode\n",
    "        model.train()\n",
    "\n",
    "        for data, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            target = target.squeeze()\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # For debug mode, calculate detailed training metrics\n",
    "            if debug_mode == 1:\n",
    "                train_loss += loss.item() * data.size(0)\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                correct_train += (predicted == target).sum().item()\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_loader:\n",
    "                output = model(data)\n",
    "                target = target.squeeze()\n",
    "                loss = criterion(output, target)\n",
    "                valid_loss += loss.item() * data.size(0)\n",
    "                _, predicted = torch.max(output.data, 1)\n",
    "                correct_valid += (predicted == target).sum().item()\n",
    "\n",
    "        # Always calculate validation accuracy\n",
    "        valid_accuracy = correct_valid / len(test_loader.dataset)\n",
    "\n",
    "        # For debug mode, print detailed metrics and check for model improvement\n",
    "        if debug_mode == 1:\n",
    "            train_loss = train_loss / len(train_loader.dataset)\n",
    "            valid_loss = valid_loss / len(test_loader.dataset)\n",
    "            train_accuracy = correct_train / len(train_loader.dataset)\n",
    "            print(f'Epoch: {epoch+1} \\tTraining Loss: {train_loss:.6f} \\tTraining Accuracy: {train_accuracy * 100:.2f}% \\tValidation Loss: {valid_loss:.6f} \\tValidation Accuracy: {valid_accuracy * 100:.2f}%')\n",
    "\n",
    "            if valid_loss < valid_loss_min:\n",
    "                print(f'Validation loss decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}).  Saving model ...')\n",
    "                torch.save(model.state_dict(), 'model.pt')\n",
    "                valid_loss_min = valid_loss\n",
    "    print(\"Test Accuracy: \")\n",
    "    return valid_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Embeddings and 3 Class MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6971"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hyperparameters_tern_custom = model_preprocess(merged_dataset['custom_vector'].values, merged_dataset['label'].values, ternary_model )\n",
    "train_model(model_hyperparameters_tern_custom, ternary_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained Embeddings and 3 Class MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.66548"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hyperparameters_tern_pre = model_preprocess(merged_dataset['pretrained_vector'].values, merged_dataset['label'].values, ternary_model)\n",
    "train_model(model_hyperparameters_tern_pre, ternary_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Embeddings and 2 Class MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.86325"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hyperparameters_bin_custom = model_preprocess(filtered_dataset['custom_vector'].values, filtered_dataset['binary_label'].values, binary_model)\n",
    "train_model(model_hyperparameters_bin_custom, binary_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained Embeddings and 2 Class MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.822525"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hyperparameters_bin_pre = model_preprocess(filtered_dataset['pretrained_vector'].values, filtered_dataset['binary_label'].values, binary_model)\n",
    "train_model(model_hyperparameters_bin_pre, binary_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) (15 points)\n",
    "What do you conclude by comparing accuracy values you obtain with\n",
    "those obtained in the “’Simple Models” section (note you can compare the\n",
    "accuracy values for binary classification)\n",
    "\n",
    "In the ternary classifiation, simple models perform worse by an average of 10% in their validation accuracies. This is due to the unique choice of hyperparamters (hidden dimensions, nonlinerity and learning etc) that pytorch allows us to customize. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained Concatenated Embeddings and 2 Class MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.786475"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hyperp_concat_bin_pre = model_preprocess(filtered_dataset['pre_concatenated_vector'].values, filtered_dataset['binary_label'].values, concat_binary_model)\n",
    "train_model(model_hyperp_concat_bin_pre, concat_binary_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Concatenated Embeddings and 2 Class MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.854975"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hyperp_concat_bin_custom = model_preprocess(filtered_dataset['custom_concatenated_vector'].values, filtered_dataset['binary_label'].values, concat_binary_model, optimi = torch.optim.SGD(concat_binary_model.parameters(), lr = 0.001))\n",
    "train_model(model_hyperp_concat_bin_custom, concat_binary_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained Concatenated Embeddings and 3 Class MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.68756"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hyperp_concat_ter_pre = model_preprocess(merged_dataset['pre_concatenated_vector'].values, merged_dataset['label'].values, concat_ternary_model, optimi = torch.optim.Adam(concat_ternary_model.parameters(), lr = 0.001))\n",
    "train_model(model_hyperp_concat_ter_pre, concat_ternary_model, n_epochs = 1, debug_mode = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Concatenated Embeddings and 3 Class MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.62498"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_hyperp_concat_ter_custom = model_preprocess(merged_dataset['custom_concatenated_vector'].values, merged_dataset['label'].values, concat_ternary_model)\n",
    "train_model(model_hyperp_concat_ter_custom, concat_ternary_model, n_epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.conv1 = nn.Conv1d(1, 50, kernel_size = 5, padding = 2) ## 50 words store as 300 dim wv's \n",
    "        self.conv2 = nn.Conv1d(50, 10, kernel_size = 5, padding = 2) \n",
    "        self.fc = nn.Linear(3000, self.num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.squeeze()  # Ensure the input indices are of type Long\n",
    "        # x = self.embedding(x).permute(0, 2, 1)\n",
    "        x = x.reshape(x.shape[0], 1 , x.shape[1])\n",
    "        x = F.gelu(self.conv1(x))\n",
    "        x = F.gelu(self.conv2(x))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom embeddings & 3 Class CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.68908"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNNnet_ter_custom_complex = SimpleCNN(num_classes = 3)\n",
    "cnn_hyperp_ter_cus = model_preprocess(x = merged_dataset['custom_vector'].values, y = merged_dataset['label'].values, model = CNNnet_ter_custom_complex, cnn_bit = 1)\n",
    "train_model(hyperparams = cnn_hyperp_ter_cus, model = CNNnet_ter_custom_complex, n_epochs = 20 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom embeddings & 2 Class CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.855325"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNNnet_bin_custom = SimpleCNN(num_classes = 2)\n",
    "cnn_hyperp_bin_cust = model_preprocess(x = filtered_dataset['custom_vector'].values, y = filtered_dataset['label'].values, model = CNNnet_bin_custom, cnn_bit = 1)\n",
    "train_model(hyperparams = cnn_hyperp_bin_cust, model = CNNnet_bin_custom, n_epochs = 15) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained embeddings & 2 Class CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8189"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNNnet_bin_pre = SimpleCNN(num_classes = 2)\n",
    "cnn_hyperp_bin_pre = model_preprocess(x = filtered_dataset['pretrained_vector'].values, y = filtered_dataset['label'].values, model = CNNnet_bin_pre, cnn_bit = 1)\n",
    "train_model(hyperparams = cnn_hyperp_bin_pre, model = CNNnet_bin_pre, n_epochs = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained embeddings & 3 Class CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.67174"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNNnet_ter_pre = SimpleCNN(num_classes = 3)\n",
    "cnn_hyperp_ter_pre = model_preprocess(x = merged_dataset['pretrained_vector'].values, y = merged_dataset['label'].values, model = CNNnet_ter_pre, cnn_bit = 1)\n",
    "train_model(hyperparams = cnn_hyperp_ter_pre, model = CNNnet_ter_pre, n_epochs = 35) # 66.71"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nuero",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
